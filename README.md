# AI-Powered Assistance for the Blind

Welcome to the AI-Powered Assistance for the Blind project! This project leverages Vision-Language Models (VLM) to provide an enhanced and interactive assistance tool for visually impaired individuals.


## Introduction

This project aims to provide a robust AI-driven assistance system for the blind, utilizing advanced Vision-Language Models (VLM). The system is designed to interpret visual data and convert it into descriptive text, which can be relayed to the user via audio, offering a seamless and intuitive user experience.

## Features

- **Image Recognition**: Identifies objects, people, and scenes.
- **Text Recognition**: Reads and vocalizes text from images.
- **Real-Time Assistance**: Provides immediate feedback and descriptions of the environment.
- **Voice Commands**: Supports voice-activated commands for hands-free operation.
- **User-Friendly Interface**: Easy-to-navigate interface designed with accessibility in mind.



## Demo Video

For a detailed demonstration of the AI-Powered Assistance for the Blind, please refer to the [demo video](Demovideo.mp3).



## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

---

Thank you for using the AI-Powered Assistance for the Blind! We hope this tool significantly improves accessibility and independence for visually impaired individuals. For any questions or support, please open an issue on the GitHub repository.
